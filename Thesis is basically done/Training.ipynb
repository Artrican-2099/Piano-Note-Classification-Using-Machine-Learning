{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(250)\n",
    "\n",
    "# Hyperparameters\n",
    "MINI_BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10\n",
    "INPUT_SIZE = 252\n",
    "NUM_UNITS = 256\n",
    "NUM_LAYERS = 4\n",
    "NUM_CLASSES = 88\n",
    "\n",
    "# File paths\n",
    "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/Datasplit/data/\"\n",
    "WEIGHTS_DIR = \"/content/drive/MyDrive/Colab Notebooks/Datasplit/weights/\"\n",
    "\n",
    "def load_data(data_path, batch_count, prefix):\n",
    "    \"\"\"Loads data batches from a directory, concatenating them along axis 0.\"\"\"\n",
    "    data, labels = [], []\n",
    "    for i in range(batch_count):\n",
    "        print(f\"Loading batch {i+1}/{batch_count} - {prefix}\")\n",
    "        data.append(np.load(os.path.join(data_path, f\"{i}{prefix}_X.npy\")))\n",
    "        labels.append(np.load(os.path.join(data_path, f\"{i}{prefix}_y.npy\")))\n",
    "    return np.concatenate(data, axis=0), np.concatenate(labels, axis=0)\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = Sequential([\n",
    "    Dense(NUM_UNITS, input_shape=(INPUT_SIZE,), activation='relu', kernel_initializer='he_normal'),\n",
    "    Dropout(0.2)\n",
    "])\n",
    "\n",
    "for i in range(1, NUM_LAYERS):\n",
    "    print(f\"Adding layer {i+1} with {NUM_UNITS} units\")\n",
    "    model.add(Dense(NUM_UNITS, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "print(\"Adding output layer for classification\")\n",
    "model.add(Dense(NUM_CLASSES, activation='sigmoid', kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "\n",
    "X_val, y_val = load_data(os.path.join(DATA_DIR, \"dev\"), batch_count=1, prefix=\"dev\")\n",
    "\n",
    "\n",
    "num_train_batches = len([name for name in os.listdir(os.path.join(DATA_DIR, \"train\"))]) // 2\n",
    "X_train, y_train = load_data(os.path.join(DATA_DIR, \"train\"), num_train_batches, prefix=\"train\")\n",
    "\n",
    "\n",
    "history = History()\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(WEIGHTS_DIR, \"weights.keras\"), verbose=1, save_best_only=False)\n",
    "\n",
    "\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=MINI_BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    "    callbacks=[history, checkpointer]\n",
    ")\n",
    "\n",
    "\n",
    "with open(\"training_log.txt\", \"w\") as log_file:\n",
    "    log_file.write(str(history.history) + \"\\n\")\n",
    "\n",
    "print(\"Training completed and log saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(250)\n",
    "\n",
    "# Hyperparameters and paths\n",
    "MINI_BATCH_SIZE = 100\n",
    "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/Datasplit/data/test/\"\n",
    "WEIGHTS_DIR = \"/content/drive/MyDrive/Colab Notebooks/Datasplit/weights/\"\n",
    "\n",
    "# Initialize lists to store data\n",
    "X, y = [], []\n",
    "\n",
    "# Load test data\n",
    "def load_test_data(data_dir, num_batches):\n",
    "    X_test, y_test = [], []\n",
    "    for i in range(num_batches):\n",
    "        print(f\"Loading batch {i+1}/{num_batches}\")\n",
    "        X_test.append(np.load(f\"{data_dir}{i}test_X.npy\"))\n",
    "        y_test.append(np.load(f\"{data_dir}{i}test_y.npy\"))\n",
    "    return np.concatenate(X_test, axis=0), np.concatenate(y_test, axis=0)\n",
    "\n",
    "num_test_batches = len([name for name in os.listdir(DATA_DIR)]) // 2\n",
    "print(\"Loading test data...\")\n",
    "X, y = load_test_data(DATA_DIR, num_test_batches)\n",
    "\n",
    "# Load model\n",
    "model = load_model(os.path.join(WEIGHTS_DIR, \"weights.keras\"))\n",
    "\n",
    "# Prediction and accuracy functions\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    TP = np.count_nonzero(np.logical_and(predictions == 1, labels == 1))\n",
    "    FN = np.count_nonzero(np.logical_and(predictions == 0, labels == 1))\n",
    "    FP = np.count_nonzero(np.logical_and(predictions == 1, labels == 0))\n",
    "    if TP + FN > 0:\n",
    "        recall = TP / float(TP + FN)\n",
    "        precision = TP / float(TP + FP)\n",
    "        accuracy = 100 * TP / float(TP + FP + FN)\n",
    "        f_measure = 100 * 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    else:\n",
    "        recall, precision, accuracy, f_measure = 0, 0, 0, 0\n",
    "    return accuracy, f_measure, recall, precision\n",
    "\n",
    "# Make predictions\n",
    "print(\"Predicting with model...\")\n",
    "predictions = model.predict(X, batch_size=MINI_BATCH_SIZE, verbose=1).round()\n",
    "predictions[predictions > 1] = 1\n",
    "np.save(f\"{WEIGHTS_DIR}predictions_CQT_DNN\", predictions)\n",
    "\n",
    "# Calculate pre-processed accuracy\n",
    "print(\"Calculating pre-processed accuracy...\")\n",
    "pre_accuracy, pre_f_measure, pre_recall, pre_precision = calculate_accuracy(predictions, y)\n",
    "print(f\"F-measure: {pre_f_measure}\")\n",
    "print(f\"Accuracy: {pre_accuracy}\")\n",
    "\n",
    "with open(os.path.join(WEIGHTS_DIR, \"Accuracy_LSTM.lst\"), \"w\") as main_data:\n",
    "    main_data.write(f\"R = {pre_recall:.6f}\\n\")\n",
    "    main_data.write(f\"P = {pre_precision:.6f}\\n\")\n",
    "    main_data.write(f\"A = {pre_accuracy:.6f}\\n\")\n",
    "    main_data.write(f\"F = {pre_f_measure:.6f}\\n\")\n",
    "\n",
    "\n",
    "print(\"Results saved to Accuracy_LSTM.lst\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
