{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Constants\n",
    "HOP_LENGTH = 512\n",
    "NBINS = 252\n",
    "BINS_OCTAVES_IN = 36\n",
    "WINDOW_STEP = 0.01\n",
    "NUM_NOTES = 88\n",
    "LENGTH_PER_FILE = 2000000\n",
    "SOURCE_FOLDER = \"/media/scar-face/Windows/Hopefully the final implementation/CQT/train\"\n",
    "OUTPUT_DIR = \"/media/scar-face/Windows/Hopefully the final implementation/CQT/train/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Global arrays\n",
    "train_to_npyarray, labels_to_npyarray = [], []\n",
    "counter_var = 0\n",
    "\n",
    "def get_folder_name(path):\n",
    "    return os.path.basename(os.path.normpath(path))\n",
    "\n",
    "def process_wav_file(wav_path, sampling_freq):\n",
    "    try:\n",
    "        _, stereo_vector = wavfile.read(wav_path)\n",
    "        mono_vector = np.mean(stereo_vector, axis=1)\n",
    "        cqt_features = np.abs(librosa.cqt(mono_vector, sr=sampling_freq, hop_length=HOP_LENGTH, n_bins=NBINS, bins_per_octave=BINS_OCTAVES_IN)).T\n",
    "        return cqt_features, np.arange(1, cqt_features.shape[0] + 1) * (HOP_LENGTH / float(sampling_freq))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {wav_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def process_csv_file(csv_path, vector_aux, num_frames):\n",
    "    labels = np.zeros((num_frames, NUM_NOTES))\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, sep='\\t')\n",
    "        if {'OnsetTime', 'OffsetTime', 'MidiPitch'}.issubset(df.columns):\n",
    "            for _, row in df.iterrows():\n",
    "                pitch_idx = int(row['MidiPitch']) - 21\n",
    "                onset_idx = np.searchsorted(vector_aux, row['OnsetTime'])\n",
    "                offset_idx = np.searchsorted(vector_aux, row['OffsetTime'] - 0.01)\n",
    "                labels[onset_idx:offset_idx, pitch_idx] = 1\n",
    "        else:\n",
    "            print(f\"CSV missing required columns: {csv_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"CSV file not found: {csv_path}\")\n",
    "    return labels\n",
    "\n",
    "def save_data(counter, data, labels, folder_name):\n",
    "    np.save(os.path.join(OUTPUT_DIR, f\"{counter}{folder_name}_X\"), data)\n",
    "    np.save(os.path.join(OUTPUT_DIR, f\"{counter}{folder_name}_y\"), labels)\n",
    "    print(f\"Saved data and labels with shape {data.shape} to {counter}{folder_name}_X.npy and {counter}{folder_name}_y.npy\")\n",
    "\n",
    "def process_directory(source_folder):\n",
    "    global train_to_npyarray, labels_to_npyarray, counter_var\n",
    "    folder_name = get_folder_name(source_folder)\n",
    "    for root, _, files in os.walk(source_folder):\n",
    "        for filename in filter(lambda f: f.endswith('.wav'), files):\n",
    "            wav_path = os.path.join(root, filename)\n",
    "            csv_path = os.path.splitext(wav_path)[0] + '.csv'\n",
    "            \n",
    "            if not os.path.exists(csv_path):\n",
    "                print(f\"CSV not found for {wav_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing {wav_path}\")\n",
    "            sampling_freq, _ = wavfile.read(wav_path)\n",
    "            cqt_features, vector_aux = process_wav_file(wav_path, sampling_freq)\n",
    "            if cqt_features is None:\n",
    "                continue\n",
    "\n",
    "            labels = process_csv_file(csv_path, vector_aux, cqt_features.shape[0])\n",
    "\n",
    "            while (len(train_to_npyarray) + len(cqt_features)) >= LENGTH_PER_FILE:\n",
    "                size_to_add = LENGTH_PER_FILE - len(train_to_npyarray)\n",
    "                train_to_npyarray.extend(cqt_features[:size_to_add])\n",
    "                labels_to_npyarray.extend(labels[:size_to_add])\n",
    "                save_data(counter_var, np.array(train_to_npyarray), np.array(labels_to_npyarray), folder_name)\n",
    "                counter_var += 1\n",
    "                train_to_npyarray, labels_to_npyarray = [], []\n",
    "                cqt_features, labels = cqt_features[size_to_add:], labels[size_to_add:]\n",
    "\n",
    "            train_to_npyarray.extend(cqt_features)\n",
    "            labels_to_npyarray.extend(labels)\n",
    "\n",
    "    if train_to_npyarray:\n",
    "        save_data(counter_var, np.array(train_to_npyarray), np.array(labels_to_npyarray), folder_name)\n",
    "process_directory(SOURCE_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "SOURCE_DIR = ''\n",
    "TRAIN_FOLDER = os.path.join(SOURCE_DIR, \"/media/scar-face/Windows/Hopefully the final implementation/Mel/train/\")\n",
    "VAL_FOLDER = os.path.join(SOURCE_DIR, \"/media/scar-face/Windows/Hopefully the final implementation/Mel/dev/\")\n",
    "TEST_FOLDER = os.path.join(SOURCE_DIR, \"/media/scar-face/Windows/Hopefully the final implementation/Mel/test/\")\n",
    "\n",
    "# Global variables to store calculated values\n",
    "mean_X, min_X, max_X = [], [], []\n",
    "\n",
    "def get_min_max_from_files(folder, file_identifier):\n",
    "    \n",
    "    for filename in filter(lambda f: file_identifier in f, os.listdir(folder)):\n",
    "        data = np.load(os.path.join(folder, filename))\n",
    "        print(f\"{filename} shape: {data.shape}\")\n",
    "        max_X.append(data.max())\n",
    "        min_X.append(data.min())\n",
    "    return max(max_X), min(min_X)\n",
    "\n",
    "def calculate_mean(folder, file_identifier, min_val, max_val):\n",
    "    total_sum, total_length = 0, 0\n",
    "    for filename in filter(lambda f: file_identifier in f, os.listdir(folder)):\n",
    "        data = np.load(os.path.join(folder, filename))\n",
    "        normalized_data = (data - min_val) / (max_val - min_val)\n",
    "        total_sum += normalized_data.sum(axis=0)\n",
    "        total_length += len(normalized_data)\n",
    "    return total_sum / total_length\n",
    "\n",
    "def normalize_and_save(folder, file_identifier, min_val, max_val, mean_val):\n",
    "    for filename in filter(lambda f: file_identifier in f, os.listdir(folder)):\n",
    "        data = np.load(os.path.join(folder, filename))\n",
    "        normalized_data = ((data - min_val) / (max_val - min_val)) - mean_val\n",
    "        save_path = os.path.join(folder, filename.split('.')[0])\n",
    "        np.save(save_path, normalized_data)\n",
    "        print(f\"Processed and saved {filename} -> {save_path}.npy\")\n",
    "\n",
    "\n",
    "print(\"Calculating max and min values from training data\")\n",
    "max_train, min_train = get_min_max_from_files(TRAIN_FOLDER, \"train_X\")\n",
    "\n",
    "print(\"Calculating mean from normalized training data\")\n",
    "train_mean = calculate_mean(TRAIN_FOLDER, \"train_X\", min_train, max_train)\n",
    "\n",
    "\n",
    "print(\"Normalizing and saving training data\")\n",
    "normalize_and_save(TRAIN_FOLDER, \"train_X\", min_train, max_train, train_mean)\n",
    "\n",
    "print(\"Normalizing and saving validation data...\")\n",
    "normalize_and_save(VAL_FOLDER, \"dev_X\", min_train, max_train, train_mean)\n",
    "\n",
    "print(\"Normalizing and saving test data...\")\n",
    "normalize_and_save(TEST_FOLDER, \"_X\", min_train, max_train, train_mean)\n",
    "\n",
    "# Output calculated values for verification\n",
    "print(f\"Train Mean:\\n{train_mean}\")\n",
    "print(f\"Train Min:\\n{min_train}\")\n",
    "print(f\"Train Max:\\n{max_train}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
